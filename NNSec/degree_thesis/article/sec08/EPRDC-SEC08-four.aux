\relax 
\immediate\closeout\minitoc
\let \MiniTOC =N
\citation{PPDM-LindellPinkas}
\citation{PPDM-Agrawal}
\citation{PPDM-LindellPinkas}
\citation{chang2005ope}
\citation{lipmaa2006svm}
\citation{kantarcioglu03privacy}
\citation{yang2005bayesian}
\citation{jha2005ppc}
\@writefile{toc}{\contentsline {title}{Enhancing Privacy in Remote Data Classification}{1}}
\@writefile{toc}{\authcount {5}}
\@writefile{toc}{\contentsline {author}{A. Piva \and C. Orlandi \unskip {} \and M. Caini \and T. Bianchi \and M. Barni}{1}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}}
\citation{ppnn}
\citation{chang2005ope}
\citation{Yao86}
\citation{lapedes1988nnw}
\citation{70408}
\citation{bishop1995nnp}
\@writefile{toc}{\contentsline {section}{\numberline {2}Neural Networks}{2}}
\newlabel{sec.NN}{{2}{2}}
\@writefile{toc}{\contentsline {paragraph}{Perceptron}{2}}
\@writefile{toc}{\contentsline {paragraph}{Feed-Forward Networks}{2}}
\citation{rumelhart1986lir}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Three kinds of different networks that can be used with the proposed protocol. Figure (a) shows a single layer network, known as {\em  perceptron}; Figure (b) shows a {\em  multi-layer feedforward network }, while Figure (c) shows a {\em  general feedforward network.} Note that in feed-forward networks it is possible to number neurons such that every neuron gets inputs only from neurons with smaller index. }}{3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Perceptron}}}{3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Multilayer network}}}{3}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(c)}{\ignorespaces {General feedforward network}}}{3}}
\newlabel{networks}{{1}{3}}
\citation{Gold87}
\citation{tor-design}
\citation{Gold87}
\@writefile{toc}{\contentsline {section}{\numberline {3}Remote Data Classification}{4}}
\newlabel{sec:RDC}{{3}{4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Protocol Requirements}{4}}
\@writefile{toc}{\contentsline {paragraph}{Correctness.}{4}}
\@writefile{toc}{\contentsline {paragraph}{Alice's Privacy.}{4}}
\citation{Kalk98}
\citation{comesana2006bns}
\citation{sander1999nic}
\citation{beaver2000mls}
\@writefile{toc}{\contentsline {paragraph}{Bob's Privacy.}{5}}
\@writefile{toc}{\contentsline {paragraph}{Round Complexity.}{5}}
\citation{rd-generalisation}
\citation{Pailler99}
\@writefile{toc}{\contentsline {section}{\numberline {4}Privacy-Preserving Protocol for Remote Data Classification}{6}}
\newlabel{sec:protocol}{{4}{6}}
\@writefile{toc}{\contentsline {paragraph}{Homomorphic Encryption.}{6}}
\newlabel{eq.hom1}{{1}{6}}
\newlabel{eq.hom2}{{2}{6}}
\@writefile{toc}{\contentsline {paragraph}{Privacy Preserving Scalar Product (PPSP).}{6}}
\newlabel{alg:PPSP}{{4}{7}}
\@writefile{toc}{\contentsline {paragraph}{Evaluation of the Activation Function}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Perceptron Protocol}{7}}
\newlabel{sec.PP}{{4.1}{7}}
\newlabel{alg:Percpetron}{{4.1}{7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Handling with Hidden Neurons}{7}}
\@writefile{toc}{\contentsline {paragraph}{Hidden Neurons Output Protection.}{7}}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces The Sigmoid is antisymmetric with respect to $(0,1/2)$, i.e. $g(-a)=1-g(a)$.}}{8}}
\newlabel{sigmoid}{{2}{8}}
\@writefile{toc}{\contentsline {paragraph}{Network Embedding.}{8}}
\@writefile{toc}{\contentsline {paragraph}{Network Randomization.}{8}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Figure (a) is a natural embedding of the network in Figure 1\hbox {} (b) into a $3\times 4$ network. The big box refers to the protected zone. The numbers under the neurons indicate which inputs are given to that neuron. Filled neurons refer to fake neurons, that are meaningless for the actual computation. In the setup phase we need to assign some inbound connection for these neurons, to be sure that their output will be undistinguishable from that of real hidden neurons. Figure (b) shows a legal scrambling of the network.}}{9}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {Network Embedding}}}{9}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {Network Scrambling}}}{9}}
\newlabel{embedding}{{3}{9}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Multi-Layer Network Protocol}{9}}
\citation{rajkovic1997}
\citation{gorman1988}
\citation{barker2005rkm}
\newlabel{alg:PPNNSigm}{{4.3}{10}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Implementation of the Protocol}{10}}
\newlabel{sec:exp}{{5}{10}}
\@writefile{toc}{\contentsline {paragraph}{Client-Server Application.}{10}}
\@writefile{toc}{\contentsline {paragraph}{Experimental Data.}{10}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Protocol execution time, according to different values of the embedding ratio.}}{11}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(a)}{\ignorespaces {\textit {Nursery} neural network}}}{11}}
\@writefile{lof}{\contentsline {subfigure}{\numberline{(b)}{\ignorespaces {\textit {Sonar} neural network}}}{11}}
\newlabel{results}{{4}{11}}
\@writefile{toc}{\contentsline {paragraph}{Experimental Setup.}{11}}
\citation{chang2005ope}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces bandwidth occupation}}{12}}
\newlabel{bwo}{{1}{12}}
\@writefile{toc}{\contentsline {paragraph}{Workload.}{12}}
\@writefile{toc}{\contentsline {section}{\numberline {6}Conclusions}{12}}
\newlabel{sec:conclusion}{{6}{12}}
\bibstyle{spmpsci}
\bibdata{EPRDC-SEC08}
\bibcite{PPDM-Agrawal}{1}
\bibcite{barker2005rkm}{2}
\bibcite{ppnn}{3}
\bibcite{beaver2000mls}{4}
\bibcite{bishop1995nnp}{5}
\bibcite{chang2005ope}{6}
\bibcite{comesana2006bns}{7}
\bibcite{rd-generalisation}{8}
\bibcite{tor-design}{9}
\bibcite{fouque2003cr}{10}
\bibcite{Gold87}{11}
\bibcite{gorman1988}{12}
\bibcite{70408}{13}
\bibcite{jha2005ppc}{14}
\bibcite{Kalk98}{15}
\bibcite{kantarcioglu03privacy}{16}
\bibcite{lapedes1988nnw}{17}
\bibcite{lipmaa2006svm}{18}
\bibcite{PPDM-LindellPinkas}{19}
\bibcite{Pailler99}{20}
\bibcite{rajkovic1997}{21}
\bibcite{rumelhart1986lir}{22}
\bibcite{sander1999nic}{23}
\bibcite{yang2005bayesian}{24}
\bibcite{Yao86}{25}
\@writefile{toc}{\contentsline {section}{References}{13}}
\@mtwritefile{\contentsline {mtchap}{References}{13}}
\citation{chang2005ope}
\citation{fouque2003cr}
\immediate\closeout\minitoc
\newlabel{appendix}{{6}{14}}
